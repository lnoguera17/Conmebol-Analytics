---
title: "Modein Conmebol"
author: "Luis Noguera"
date: "5/31/2020"
output: html_document
---

# Data Load

```{r}

source("Data Cleaning Script.R")


```


# Data Split

```{r}

set.seed(415)

# Split data into training and testing data sets. 
conmebol_split <- initial_split(conmebol, prop = .8, strata = foot)
conmebol_train <- training(conmebol_split) 
conmebol_test <- testing(conmebol_split)


```


# Fitting Statistical Models - 

- Linear Regression Model
- Linear Regression Model with data Pre-processing. 
- Regularization Model - Lasso Regression
- Random Forest Model - XGBoost

## Linear Regression Model - (Using this model as baseline)

```{r}
set.seed(415)
linear_fit <- lm(value ~ . -id, data = conmebol_train)
summary(linear_fit)

```


Adjusted R-Squared - 0.69
Residual Standard Error -  $5,503,000

This simple linear model serves as a guideline to improve future statistical models.


## Data Pre-Processing 

How far can we go with a simple linear model and working on data pre-processing. 

The following pre-processings steps have been performed.

- Log transformed the predictor variable *Value* of the player.

- Removed highly correlated features to prevent multicolinearity. 

- Narrowed *best_position* feature to values with a rate of ocurrance greater than 5%.

- Created dummy variable for all categorical variables.

- Impute the outcome *Value* using K-Nearest Neighbors.

- Centered and scaled all predictors.

- Removed possible variables that could contain a single value.

- Removed the *id* variable

```{r}

conmebol_rec <- recipe(value ~ ., data = conmebol_train) %>%
  update_role(id, new_role = 'id') %>%  
  step_log(all_outcomes()) %>%
  step_corr(all_numeric(), -all_outcomes()) %>%
  step_other(best_position, threshold = 0.05) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_knnimpute(value, neighbors = 5) %>%
  step_normalize(all_predictors(), -all_outcomes())  %>%
  step_zv(all_predictors()) 

conmebol_prep <- conmebol_rec %>% prep()

conmebol_train_proc <- bake(conmebol_prep, conmebol_train) %>% select(-id)
conmebol_test_proc <- bake(conmebol_prep, conmebol_test) %>% select(-id)

  
```

## Linear Regression Model after Data Pre-Processing

**Linear Regression model with Pre-processed Data**

Results look promising with a simple linear regression after doing data pre-processing. However, results on the training data set suggest the model has severely overfited the training data. 

```{r}

linear_fit_proc <- lm(value ~., data = conmebol_train_proc)
summary(linear_fit_proc)

linear_fit_proc_pred <- predict(linear_fit_proc, conmebol_test_proc) %>%
  as.data.frame() %>%
  mutate(pred = exp(.)) %>%
  bind_cols(conmebol_test_proc) %>%
  mutate(truth = exp(value)) %>%
  select(pred, truth) 


# Root Mean Squared Error Function
RMSE = function(m, o){
  sqrt(mean((m - o)^2))
}


attach(linear_fit_proc_pred)
rmse_test <- scales::comma(RMSE(pred, truth))

```

Root Mean Squared Error on the Validation Set. 

`r rmse_test`


## Regularization Models - Lasso Regression - (Book)

```{r}


X <- model.matrix(value ~ ., conmebol_train_proc)[, -1]

Y <- (conmebol_train_proc$value)



ridge <- cv.glmnet(
  x = X,
  y = Y,
  alpha = 0
)

plot(ridge, xvar = "lambda")


lasso <- cv.glmnet(
  x = X,
  y = Y,
  alpha = 1
)


par(mfrow = c(1, 2))
plot(ridge, main = "Ridge penalty\n\n")
plot(lasso, main = "Lasso penalty\n\n")
```


```{r}

# Ridge model
ridge_min <- glmnet(
  x = X,
  y = Y,
  alpha = 0
)

# Lasso model
lasso_min <- glmnet(
  x = X,
  y = Y,
  alpha = 1
)


par(mfrow = c(1, 2))
# plot ridge model
plot(ridge_min, xvar = "lambda", main = "Ridge penalty\n\n")
abline(v = log(ridge$lambda.min), col = "red", lty = "dashed")
abline(v = log(ridge$lambda.1se), col = "blue", lty = "dashed")

# plot lasso model
plot(lasso_min, xvar = "lambda", main = "Lasso penalty\n\n")
abline(v = log(lasso$lambda.min), col = "red", lty = "dashed")
abline(v = log(lasso$lambda.1se), col = "blue", lty = "dashed")
```


## Lasso Regression - Tidymodels

Creating resample training dataset and lambda grid for penalization.

```{r}
set.seed(415)

wf <- workflow() %>%
  add_recipe(conmebol_rec)


# Creating bootstraps of training data to 
conmebol_boot <- bootstraps(conmebol_train)


lasso_spec <- linear_reg(mode = 'regression', 
                         penalty = tune(),
                         mixture = 1) %>%
  set_engine('glmnet')


lambda_grid <- grid_regular(penalty(), levels = 50)


```


### Fitting resampled data and collecting metrics 

```{r}



lasso_grid <- tune_grid(
  wf %>%
  add_model(lasso_spec),
  resamples = conmebol_boot,
  grid = lambda_grid
)



lasso_tune_results <- lasso_grid %>%  collect_metrics()
lasso_tune_results

```



### Visualizing evalutaion metrics with penalization 

```{r}


lasso_tune_results %>% 
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size  = 1) +
  facet_wrap(~.metric, scales = 'free', nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none")
  

```

### Finalizing Lasso Model

```{r}


highest_rsq <- lasso_grid %>%
  select_best('rsq')

final_lasso <- finalize_workflow(
  wf %>%
  add_model(lasso_tune),
  highest_rsq
)


```

### Variable Importance with Lasso Model

```{r}

library(vip)

final_lasso %>%
  fit(conmebol_train) %>%
  pull_workflow_fit() %>%
  vi(lambda = highest_rsq$penalty)%>%
  mutate(
    Importance = abs(Importance),
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)



```

### Final Lasso Fit

Evaluating on validation set. Not so great results.

*Important*
Unsure about rmse results since the outcome is log transformed. 

```{r}

final_lasso_fit <- last_fit(final_lasso,
         conmebol_split) %>%
  collect_metrics() 

final_lasso_fit


```



