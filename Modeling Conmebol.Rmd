---
title: "Modein Conmebol"
author: "Luis Noguera"
date: "5/31/2020"
output: html_document
---

# Data Load

```{r}

source("Data Cleaning Script.R")

Conmebol_model<- Conmebol %>% 
  select(-id, -name, -height, -value2)
  
```


# Data Split

```{r}

set.seed(415)

# Split data into training and testing data sets. 
conmebol_split <- initial_split(Conmebol_model, prop = .8, strata = best_position)
conmebol_train <- training(conmebol_split) 
conmebol_test <- testing(conmebol_split)


# Creating bootstraps of training data to perform re-sampling and tuning methods
conmebol_boot <- bootstraps(conmebol_train)

```

# Fitting Statistical Models - 

- Linear Regression Model - Use as baseline
- Linear Regression Model with data Pre-processing. 
- Random Forest Model - XGBoost

## Linear Regression Model - (Using this model as baseline)

```{r}
set.seed(415)
linear_fit <- lm(value ~ ., data = conmebol_train)
summary(linear_fit)


# Residual Mean Squared Error of Baseline Model
linear_fit %>%
  predict(conmebol_train) %>%
  as_tibble() %>%
  mutate(truth = replace_na(conmebol_train$value, 0),
         model = "Linear Model Baseline") %>%
  rename("estimate" = "value") %>%
  rmse(truth = truth, estimate = estimate) 

```

On the Training Data
Adjusted R-Squared - 0.69
Residual Mean Squared Error - *EU 6,150,279*


This simple linear model serves as a guideline to improve future statistical models.


## Data Pre-Processing 

How far can we go with a simple linear model and working on data pre-processing. 

The following pre-processing steps have been performed.

- Removed highly correlated features to prevent multicolinearity. 

- Created two variables for *high* and *low* value Outliers

- Narrowed *best_position* feature to values with a rate of occurrence greater than 5%.

- Created dummy variable for all categorical variables.

- Impute the outcome *Value* using K-Nearest Neighbors.

- Centered and scaled all predictors.

- Removed possible variables that could contain a single value.

- Removed the *id* variable

```{r}

conmebol_rec <- recipe(value ~ ., data = conmebol_train) %>%
  step_mutate(value_outliers_hi = case_when(value > 60000000 ~ 1, 
                                            TRUE ~ 0)) %>%
  step_mutate(value_outliers_lo = case_when(value < 300000 ~ 1,
                                            TRUE ~ 0)) %>%
  step_corr(all_numeric(), -all_outcomes()) %>%
  step_other(best_position, threshold = 0.05) %>%
  step_dummy(all_nominal(), -all_outcomes()) %>%
  step_knnimpute(value, neighbors = 5) %>%
  step_normalize(all_predictors(), -all_outcomes())  %>%
  step_zv(all_predictors()) 

conmebol_prep <- conmebol_rec %>% prep()

conmebol_train_proc <- bake(conmebol_prep, conmebol_train) 
conmebol_test_proc <- bake(conmebol_prep, conmebol_test) 

  
```

# Linear Model with pre-processed data

```{r}

lin_mod_spec <- linear_reg() %>%
  set_mode('regression') %>%
  set_engine('lm')

linear_fit_proc <- lin_mod_spec %>%
  fit(value ~.,
      data = conmebol_train_proc)

tidy_results_linear <- linear_fit_proc %>%
  tidy() %>%
  arrange(p.value) %>%
  View()

tidy_results_linear
```

# Random Forest Model


```{r}

rf_mod_spec <- rand_forest() %>%
  set_mode('regression') %>%
  set_engine('ranger')
  
rf_fit_proc <- rf_mod_spec %>%
  fit(value ~ ., 
      data = conmebol_train_proc)

rf_fit_proc

```

## Model Evaluation

**Training Data Evaluation**

```{r}

results_train <- linear_fit_proc %>%
  predict(conmebol_train_proc) %>%
  mutate(truth = conmebol_train_proc$value,
         model = "Linear Model") %>%
  bind_rows(rf_fit_proc %>%
  predict(conmebol_train_proc) %>%
  mutate(truth = conmebol_train_proc$value,
         model = "Random Forest"))
  
results_train  %>%
  group_by(model) %>%
  rmse(truth = truth, estimate = .pred)
  
```

**Testing Data Evaluation**

```{r}

testing_train <- linear_fit_proc %>%
  predict(conmebol_test_proc) %>%
  mutate(truth = conmebol_test_proc$value,
         model = "Linear Model") %>%
  bind_rows(rf_fit_proc %>%
  predict(conmebol_test_proc) %>%
  mutate(truth = conmebol_test_proc$value,
         model = "Random Forest"))
  
testing_train  %>%
  group_by(model) %>%
  rmse(truth = truth, estimate = .pred)

```

## Hyperparameter Tuning? 






# Code below - TBD 


## Regularization Models - Lasso Regression - (Book)

```{r}


X <- model.matrix(value ~ ., conmebol_train_proc)[, -1]

Y <- (conmebol_train_proc$value)



ridge <- cv.glmnet(
  x = X,
  y = Y,
  alpha = 0
)

plot(ridge, xvar = "lambda")


lasso <- cv.glmnet(
  x = X,
  y = Y,
  alpha = 1
)


par(mfrow = c(1, 2))
plot(ridge, main = "Ridge penalty\n\n")
plot(lasso, main = "Lasso penalty\n\n")
```


```{r}

# Ridge model
ridge_min <- glmnet(
  x = X,
  y = Y,
  alpha = 0
)

# Lasso model
lasso_min <- glmnet(
  x = X,
  y = Y,
  alpha = 1
)


par(mfrow = c(1, 2))
# plot ridge model
plot(ridge_min, xvar = "lambda", main = "Ridge penalty\n\n")
abline(v = log(ridge$lambda.min), col = "red", lty = "dashed")
abline(v = log(ridge$lambda.1se), col = "blue", lty = "dashed")

# plot lasso model
plot(lasso_min, xvar = "lambda", main = "Lasso penalty\n\n")
abline(v = log(lasso$lambda.min), col = "red", lty = "dashed")
abline(v = log(lasso$lambda.1se), col = "blue", lty = "dashed")
```


## Lasso Regression - Tidymodels

Creating resample training dataset and lambda grid for penalization.

```{r}
set.seed(415)

wf <- workflow() %>%
  add_recipe(conmebol_rec)


lasso_spec <- linear_reg(mode = 'regression', 
                         penalty = tune(),
                         mixture = 1) %>%
  set_engine('glmnet')


lambda_grid <- grid_regular(penalty(), levels = 5)


```


### Fitting resampled data and collecting metrics 

```{r}



lasso_grid <- tune_grid(
  wf %>%
  add_model(lasso_spec),
  resamples = conmebol_boot,
  grid = lambda_grid
)



lasso_tune_results <- lasso_grid %>%  collect_metrics()
lasso_tune_results

```

### Visualizing evalutaion metrics with penalization 

```{r}


lasso_tune_results %>% 
  ggplot(aes(penalty, mean, color = .metric)) +
  geom_errorbar(aes(
    ymin = mean - std_err,
    ymax = mean + std_err
  ),
  alpha = 0.5
  ) +
  geom_line(size  = 1) +
  facet_wrap(~.metric, scales = 'free', nrow = 2) +
  scale_x_log10() +
  theme(legend.position = "none")
  

```

### Finalizing Lasso Model

```{r}


highest_rsq <- lasso_grid %>%
  select_best('rsq')

final_lasso <- finalize_workflow(
  wf %>%
  add_model(lasso_tune),
  highest_rsq
)


```

### Variable Importance with Lasso Model

```{r}

library(vip)

final_lasso %>%
  fit(conmebol_train) %>%
  pull_workflow_fit() %>%
  vi(lambda = highest_rsq$penalty)%>%
  mutate(
    Importance = abs(Importance),
    Variable = fct_reorder(Variable, Importance)
  ) %>%
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)



```

### Final Lasso Fit

Evaluating on validation set. Not so great results.

*Important*
Unsure about rmse results since the outcome is log transformed. 

```{r}

final_lasso_fit <- last_fit(final_lasso,
         conmebol_split) %>%
  collect_metrics() 

final_lasso_fit


```



